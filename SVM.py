# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_7OLUUV5PUlwRIW8kskSBDWkK5BQXIRF
"""

import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC

# Încărcarea datelor de antrenament
train_data = pd.read_csv('/content/train.csv')

# Separarea caracteristicilor și a etichetei țintă
X_train = train_data.drop(['id', 'is_anomaly'], axis=1)  # Elimină coloanele 'id' și 'is_anomaly'
y_train = train_data['is_anomaly']                       # Extrage eticheta țintă 'is_anomaly'

# Standardizarea caracteristicilor
scaler = StandardScaler()                                # Inițializează un obiect StandardScaler
X_train = scaler.fit_transform(X_train)                  # Standardizează datele de antrenament

# Inițializarea modelului SVM
model = SVC(kernel='rbf', class_weight='balanced', probability=True)  # Creează modelul SVM cu kernel RBF
model.fit(X_train, y_train) # Antrenarea modelului SVM pe datele de antrenament

# Încărcarea datelor de test
test_data = pd.read_csv('/content/test.csv')

# Separarea caracteristicilor pentru datele de test
X_test = test_data.drop(['id'], axis=1)                  # Elimină coloana 'id'
X_test = scaler.transform(X_test)                        # Standardizează datele de test

# Realizarea predicțiilor pe datele de test
test_predictions = model.predict(X_test)                 # Face predicții folosind modelul antrenat

# Crearea unui DataFrame pentru submisie
submission = pd.DataFrame({ 'id': test_data['id'], 'is_anomaly': test_predictions})
                            # Include id-ul      # Include predicțiile pentru anomalii



# Salvarea DataFrame-ului de submisie într-un fișier CSV
submission.to_csv('submission.csv', index=False)